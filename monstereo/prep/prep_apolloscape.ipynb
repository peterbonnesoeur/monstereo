{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "from utils import append_cluster, correct_angle, normalize_hwl, pixel_to_camera, to_spherical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "\n",
    "#from network.process import preprocess_pifpaf, preprocess_monoloco\n",
    "\n",
    "from utils import K, KPS_MAPPING,car_name2id, car_id2name, intrinsic_vec_to_mat, euler_angles_to_rotation_matrix, \\\n",
    "                                rotation_matrix_to_euler_angles, convert_pose_mat_to_6dof, project, pose_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(KPS_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"train\"\n",
    "\n",
    "annotations = False\n",
    "\n",
    "kps_3d = False\n",
    "buffer = 20\n",
    "radius = 200\n",
    "dir_ann =\"/data/maxime-data/apollo-pifpaf\"\n",
    "dir_apollo =\"/data/maxime-data/apolloscape\"\n",
    "dir_out = \"/home/maximebonnesoeur/monstereo/data/arrays/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_3d_extract(vertices):\n",
    "    min_x = np.min(vertices[:,0])\n",
    "    max_x= np.max(vertices[:,0])\n",
    "    min_y = np.min(vertices[:,1])\n",
    "    max_y= np.max(vertices[:,1])\n",
    "    min_z = np.min(vertices[:,2])\n",
    "    max_z= np.max(vertices[:,2])\n",
    "    \n",
    "    bbox_3d=[]\n",
    "    for x in [min_x, max_x]:\n",
    "        for y in [min_y, max_y]:\n",
    "            for z in [min_z, max_z]:\n",
    "                bbox_3d.append([x,y,z])\n",
    "    return(np.array(bbox_3d))\n",
    "\n",
    "\n",
    "def extract_box_average(boxes_3d):\n",
    "    boxes_np = np.array(boxes_3d)\n",
    "    means = np.mean(boxes_np[:, 3:], axis=0)\n",
    "    stds = np.std(boxes_np[:, 3:], axis=0)\n",
    "    print(means)\n",
    "    print(stds)\n",
    "\n",
    "\n",
    "def kps_apolloscape_to_monoloco(kps, kps_3d = False):\n",
    "    new_kps = []\n",
    "    for i in range(67):\n",
    "        if i not in kps[:,0]:\n",
    "            new_kps.append([i, -100, -100, -100])\n",
    "        else:\n",
    "            new_kps.append(kps[np.where(kps[:,0] == i)[0], :][0])\n",
    "    new_kps = np.array(new_kps)\n",
    "    \n",
    "    new_kps = new_kps[KPS_MAPPING] if kps_3d else new_kps[KPS_MAPPING][:,:3] #Remove or let the third dimension\n",
    "    \n",
    "    for i in range(len(new_kps)):\n",
    "        if new_kps[i,1] < 0:\n",
    "            new_kps[i, 0] = 0.0 # If the keypoint is not visible in the dataset, the confidence is of 0\n",
    "        else:\n",
    "            new_kps[i, 0] = 1.0 #Â If the keypoint is visible in the dataset, its confidence is of 1.0\n",
    "        \n",
    "    if kps_3d:\n",
    "        return new_kps[:,[1,2,3,0]]\n",
    "    else:\n",
    "        return new_kps[:,[1,2,0]]\n",
    "\n",
    "def kps_pifpaf_apolloscape_to_monoloco(kps, kps_3d = False):\n",
    "    # Convert the pifpaf keypoints in the appropriate formatting for monolocopp\n",
    "    \n",
    "    new_kps = []\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def keypoints_to_cad_model(keypoints, vertices_cad_dic, radius = 160):\n",
    "    # Associate for each CAD model a set of keypoints\n",
    "    keypoints_to_cad = {}\n",
    "    num_keypoints = len(keypoints)\n",
    "    if annotations :\n",
    "        print(\"NUM_KEYPOINTS\",num_keypoints)\n",
    "    if len(keypoints.shape) == 1:\n",
    "        keypoints = [keypoints]\n",
    "    \n",
    "    \n",
    "    for i, vertices_2d in vertices_cad_dic.items():\n",
    "        \n",
    "        \n",
    "        for j, keypoint in enumerate(keypoints):\n",
    "            \n",
    "            #print(\"vertices\", [vertices[:,0]/vertices[:,2], vertices[:,1]/vertices[:,2]])\n",
    "            #print(\"KEYPOINTS - 1\",keypoints)\n",
    "            #print(np.ones([len(vertices),2])*keypoint[1:])\n",
    "            res = np.ones([len(vertices_2d),2])*keypoint[1:] - np.transpose([vertices_2d[:,0]/vertices_2d[:,2], vertices_2d[:,1]/vertices_2d[:,2]])\n",
    "            dist = np.min( np.linalg.norm(res, axis = 1 ))\n",
    "            \n",
    "            if i == 0 and dist < radius:\n",
    "                keypoints_to_cad[j] = [i, dist]\n",
    "            elif i == 0 and dist >= radius:\n",
    "                keypoints_to_cad[j] = [-1, np.infty]\n",
    "                \n",
    "            elif dist < keypoints_to_cad[j][1] and dist <= radius:\n",
    "                keypoints_to_cad[j] = [i, dist]\n",
    "                \n",
    "    \n",
    "    count = 0\n",
    "    result = -1\n",
    "    \n",
    "    a = np.array( list( keypoints_to_cad.values()))[:,0]\n",
    "    index, counts = np.unique(a, return_counts=True)\n",
    "    \n",
    "    return keypoints_to_cad, index[np.argmax(counts)], np.max(counts)\n",
    "\n",
    "def keypoint_expander(vertices_2d, keypoints, buffer = 100) :\n",
    "    #process the existing keypoints and assign them a depth by minimizing the \n",
    "    #distance with the vertices of the projected CAD models.\n",
    "    new_keypoints =[]\n",
    "    if len(keypoints.shape) == 1:\n",
    "        keypoints = [keypoints]\n",
    "        \n",
    "    for keypoint in keypoints:\n",
    "        if len(keypoint)<2:\n",
    "            print(\"ouch\")\n",
    "        if len(vertices_2d[0])<2:\n",
    "            print(\"ouch 2\")\n",
    "            \n",
    "            \n",
    "        res = np.ones([len(vertices_2d),2])*keypoint[1:] - np.transpose([vertices_2d[:,0]/vertices_2d[:,2], vertices_2d[:,1]/vertices_2d[:,2]])\n",
    "        \n",
    "        dist = np.linalg.norm(res, axis = 1)\n",
    "        \n",
    "        z = np.min(vertices_2d[np.argsort(dist)[0:buffer], 2])\n",
    "        \n",
    "        \n",
    "        new_keypoints.append([keypoint[0], keypoint[1], keypoint[2], z])\n",
    "        \n",
    "    return np.array(new_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def keypoint_projection(keypoints_3D_img, intrinsic_matrix) :\n",
    "    #take the keypoints in the 2D space form the ground truth and reproject them in the 3D space.\n",
    "    \n",
    "    keypoints_3D_img = np.array(keypoints_3D_img)\n",
    "    keypoints_3D_img[:,1] = keypoints_3D_img[:,1] *keypoints_3D_img[:,3]\n",
    "    keypoints_3D_img[:,2] = keypoints_3D_img[:,2] *keypoints_3D_img[:,3]\n",
    "    keypoints_3D = np.matmul(np.array(keypoints_3D_img)[:,1:], np.linalg.pinv(intrinsic_matrix.transpose())) # The firs element is the index of the keypoints\n",
    "\n",
    "    return np.array( keypoints_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_3d_extract(vertices):\n",
    "    \n",
    "    min_x = np.min(vertices[:,0])\n",
    "    max_x= np.max(vertices[:,0])\n",
    "    min_y = np.min(vertices[:,1])\n",
    "    max_y= np.max(vertices[:,1])\n",
    "    min_z = np.min(vertices[:,2])\n",
    "    max_z= np.max(vertices[:,2])\n",
    "    \n",
    "    h = max_y - min_y\n",
    "    w = max_x - min_x\n",
    "    l = max_z- min_z\n",
    "    \n",
    "    bbox_3d=[]\n",
    "    for x in [min_x, max_x]:\n",
    "        for y in [min_y, max_y]:\n",
    "            for z in [min_z, max_z]:\n",
    "                bbox_3d.append([x,y,z])\n",
    "                \n",
    "    \n",
    "    return(np.array(bbox_3d), w, l, h)\n",
    "\n",
    "def bbox_gt_extract(bbox_3d, kk):\n",
    "    zc = np.mean(bbox_3d[:,2])\n",
    "    \n",
    "    #take the top right corner and the bottom left corner of the bounding box in the 3D spac\n",
    "    corners_3d = np.array([[np.min(bbox_3d[:,0]), np.min(bbox_3d[:,1]), zc], [np.max(bbox_3d[:,0]), np.max(bbox_3d[:,1]), zc] ])\n",
    "    \n",
    "    box_2d = []\n",
    "    \n",
    "    for xyz in corners_3d:\n",
    "        xx, yy, zz = np.dot(kk, xyz)\n",
    "        uu = xx / zz\n",
    "        vv = yy / zz\n",
    "        box_2d.append(uu)\n",
    "        box_2d.append(vv)\n",
    "\n",
    "    return box_2d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_projection( car_model, scale , T, turn_over = False, bbox= False):\n",
    "    # perform the projection of the CAD models of the cars in the 3D space (use car_models_json)\n",
    "    with open(car_model) as json_file:\n",
    "        data = json.load(json_file) #Loading of the vehicle CAD model\n",
    "        vertices = np.array(data['vertices']) # extraction of the vertices\n",
    "\n",
    "        if (turn_over): # used to turn the vehicle over its z axis (180 degree turn) \n",
    "                        # It was shown that the pose estimation have a precomputed rotation of the carts over their z axis \n",
    "                        # Reminder: the z axis is the one of the depth\n",
    "            z_rot = np.array([0.,0., np.pi, 0.0,0.0,0.0])\n",
    "            vertices = project(z_rot, scale, vertices) #Pre-rotation of the vehicle over its z axis\n",
    "        \n",
    "        \n",
    "        vertices_r = project(T, scale, vertices) #projection in the 3D space\n",
    "        triangles = np.array(data['faces']) - 1      \n",
    "        results = vertices_r, triangles\n",
    "        \n",
    "        if bbox:\n",
    "            bbox_3d, w, l, h= bbox_3d_extract(vertices)\n",
    "            bbox_3d_r = project(T, scale, bbox_3d)      # Place the bounding box at its place in the 3D space\n",
    "            \n",
    "            results = vertices_r, triangles, bbox_3d_r, w, l, h\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_monoloco(keypoints, kk, zero_center=False):\n",
    "\n",
    "    \"\"\" Preprocess batches of inputs\n",
    "    keypoints = torch tensors of (m, 3, 17)  or list [3,17]\n",
    "    Outputs =  torch tensors of (m, 34) in meters normalized (z=1) and zero-centered using the center of the box\n",
    "    \"\"\"\n",
    "    if isinstance(keypoints, list):\n",
    "        keypoints = torch.tensor(keypoints).double()\n",
    "    if isinstance(kk, list):\n",
    "        kk = torch.tensor(kk).double()\n",
    "    # Projection in normalized image coordinates and zero-center with the center of the bounding box\n",
    "    \n",
    "    xy1_all = pixel_to_camera(keypoints[:, 0:2, :], kk, 10)\n",
    "    \n",
    "    if zero_center:\n",
    "        uv_center = get_keypoints(keypoints, mode='center')\n",
    "        xy1_center = pixel_to_camera(uv_center, kk, 10)\n",
    "       \n",
    "    \n",
    "        kps_norm = xy1_all - xy1_center.unsqueeze(1)  # (m, 17, 3) - (m, 1, 3)\n",
    "    else:\n",
    "        kps_norm = xy1_all\n",
    "    kps_out = kps_norm[:, :, 0:2].reshape(kps_norm.size()[0], -1)  # no contiguous for view\n",
    "    # kps_out = torch.cat((kps_out, keypoints[:, 2, :]), dim=1)\n",
    "    return kps_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "yaw = math.pi\n",
    "\n",
    "yaw = yaw%np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessApolloscape:\n",
    "\n",
    "\n",
    "    \"\"\"Preprocess apolloscape dataset\"\"\"\n",
    "\n",
    "\n",
    "    dic_jo = {'train': dict(X=[], Y=[], names=[], kps=[], boxes_3d=[], K=[],\n",
    "                            clst=defaultdict(lambda: defaultdict(list))),\n",
    "              'val': dict(X=[], Y=[], names=[], kps=[], boxes_3d=[], K=[],\n",
    "                          clst=defaultdict(lambda: defaultdict(list))),\n",
    "                          }\n",
    "    dic_names = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    def __init__(self, dir_ann, dir_apollo, dir_out, dataset, kps_3d = False,buffer=20, radius=200):\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        self.buffer = buffer\n",
    "        self.radius = radius\n",
    "        \n",
    "        self.kps_3d = kps_3d\n",
    "        \n",
    "        self.dir_ann = dir_ann\n",
    "        #dir_out = os.path.join('data', 'arrays')\n",
    "        assert os.path.exists(dir_apollo), \"apollo directory does not exists\"\n",
    "        assert os.path.exists(self.dir_ann), \"The annotations directory does not exists\"\n",
    "        assert os.path.exists(dir_out), \"Joints directory does not exists\"\n",
    "\n",
    "        now = datetime.datetime.now()\n",
    "        now_time = now.strftime(\"%Y%m%d-%H%M\")[2:]\n",
    "        self.path_joints = os.path.join(dir_out, 'joints-' + dataset + '-' + now_time + '.json')\n",
    "        self.path_names = os.path.join(dir_out, 'names-' + dataset + '-' + now_time + '.json')\n",
    "\n",
    "        \n",
    "        self.path  = os.path.join(dir_apollo, dataset)\n",
    "        self.scenes, self.train_scenes, self.validation_scenes = factory(dataset, dir_apollo)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def extract_ground_truth(self, car_poses,camera_id, scene_id):\n",
    "        \n",
    "        with open(car_poses) as json_file:\n",
    "            data = json.load(json_file) #open the pose of the cars\n",
    "\n",
    "        dic_vertices = {}\n",
    "        dic_boxes = {}\n",
    "        dic_poses = {}\n",
    "        vertices_to_keypoints = {}\n",
    "        dic_keypoints = {}\n",
    "\n",
    "        #Extract the boxes, vertices and the poses of each cars                   \n",
    "        for car_index, car in enumerate(data):\n",
    "            name_car = car_id2name[car['car_id']].name \n",
    "            car_model = os.path.join(self.path, \"car_models_json\",name_car+\".json\")\n",
    "\n",
    "            intrinsic_matrix = intrinsic_vec_to_mat(K[\"Camera_\"+camera_id])\n",
    "\n",
    "            vertices_r, triangles, bbox_3d , w, l, h = car_projection(car_model, np.array([1,1,1]), T = np.array(car['pose']),  turn_over = True, bbox = True\n",
    "                                                           )\n",
    "            vertices_2d = np.matmul(vertices_r,intrinsic_matrix.transpose()) # Projected vertices on the 2D plane\n",
    "            \n",
    "            box_gt = bbox_gt_extract(bbox_3d, intrinsic_matrix)  # Take the overal bounding box in the 2D space\n",
    "            \n",
    "            dic_vertices[car_index] = vertices_2d\n",
    "            dic_boxes[car_index] = [box_gt, w, l, h]\n",
    "            dic_poses[car_index] = np.array(car['pose'])\n",
    "\n",
    "        new_keypoints = None\n",
    "        \n",
    "        #  print(\"DIC_BOXES\", dic_boxes)\n",
    "                           \n",
    "        if \"sample\" not in self.path:\n",
    "                           \n",
    "            car_keypoints = os.path.join(self.path, \"keypoints\", scene_id)\n",
    "            \n",
    "            keypoints_list = []\n",
    "            boxes_gt_list = []  # Countain the the 2D bounding box of the vehicles\n",
    "            boxes_3d_list = []\n",
    "            ys_list = []               \n",
    "            \n",
    "            #Compute the similarity between each set of car models in the 3D space and the set of keypoints in the 2D space\n",
    "            for index_keypoints, file in enumerate(os.listdir(car_keypoints)):\n",
    "                if file.endswith(\".txt\"):\n",
    "                    keypoints = np.loadtxt(os.path.join(car_keypoints, file))\n",
    "\n",
    "                    dic_keypoints[index_keypoints] = keypoints\n",
    "\n",
    "                    k_t_c, index_cad, count = keypoints_to_cad_model(keypoints, dic_vertices, radius = self.radius)\n",
    "\n",
    "                    if index_cad not in vertices_to_keypoints.keys():\n",
    "                        vertices_to_keypoints[index_cad] = [index_keypoints, count, k_t_c]\n",
    "                    elif vertices_to_keypoints[index_cad][1] < count:\n",
    "                        vertices_to_keypoints[index_cad] = [index_keypoints, count, k_t_c]\n",
    "            \n",
    "            for index_cad, (index_keypoints, count, k_t_c) in vertices_to_keypoints.items()   :\n",
    "\n",
    "                if (index_cad != -1 and count >=1):\n",
    "\n",
    "                    keypoints = dic_keypoints[index_keypoints]\n",
    "                    vertices_2d = dic_vertices[index_cad]\n",
    "                    new_keypoints = keypoint_expander(vertices_2d, keypoints, self.buffer)\n",
    "                    #Pixel keypoints with a Z component\n",
    "                    \n",
    "                    #Return an ordered list of the keypoints in the 3D space, their Bounding box in the 3D space and their pose in the 3D space\n",
    "                    keypoints_list.append(kps_apolloscape_to_monoloco( new_keypoints, kps_3d = self.kps_3d))\n",
    "                    \n",
    "                    \n",
    "                    boxes_gt_list.append(dic_boxes[index_cad][0]) #2D corners of the bounding box\n",
    "                    \n",
    "                    #print(\"EXTRACT THIS\",dic_boxes[index_cad][1:])\n",
    "                    \n",
    "                    w, l, h = dic_boxes[index_cad][1:]\n",
    "                    pitch, yaw, roll, xc, yc, zc = dic_poses[index_cad] # Center position of the car and its orientation\n",
    "                    \n",
    "                    boxes_3d_list.append([xc, yc, zc, w, l, h])\n",
    "                    \n",
    "                    # CHECK IF IT IS PI or 2PI\n",
    "                    yaw = yaw%np.pi\n",
    "                    \n",
    "                    sin, cos, _ = correct_angle(yaw, [xc, yc, zc])\n",
    "                    \n",
    "                    if True :\n",
    "                        rtp = to_spherical([xc, yc, zc])\n",
    "                        theta, psi, r = rtp # With r =d = np.linalg.norm([xc,yc,zc]) -> conversion to spherical coordinates \n",
    "                        ys_list.append([theta, psi, r, zc, h, w, l, sin, cos, yaw])\n",
    "                    else:\n",
    "                        ys_list.append([xc, yc, zc, np.linalg.norm([xc, yc, zc]), h, w, l, sin, cos, yaw])\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            return boxes_gt_list, boxes_3d_list, keypoints_list, ys_list\n",
    "        \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for index_cad, _ in dic_vertices.items() :\n",
    "                \n",
    "                boxes_gt_list.append(dic_boxes[index_cad][0]) #2D corners of the bounding box\n",
    "                    \n",
    "                w, l, h = dic_boxes[index_cad][1:]\n",
    "                pitch, yaw, roll, xc, yc, zc = dic_poses[index_cad] # Center position of the car and its orientation\n",
    "\n",
    "                boxes_3d_list.append([xc, yc, zc, w, l, h])\n",
    "                yaw = yaw%np.pi\n",
    "\n",
    "                ys_list.append([xc, yc, zc, np.linalg.norm([xc, yc, zc]), h, w, l, np.sin(yaw), np.cos(yaw), yaw])\n",
    "            \n",
    "            \n",
    "            return boxes_gt_list, boxes_3d_list, None, ys_lists\n",
    "    \n",
    "                    \n",
    "    def extract_ground_truth_pifpaf(car_poses,camera_id, scene_id):\n",
    "        pass\n",
    "            \n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Prepare arrays for training\n",
    "        \"\"\"\n",
    "        cnt_scenes  = cnt_ann = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        for ii, scene in enumerate(self.scenes):\n",
    "            \n",
    "            if ii==-100:\n",
    "                print(\"BREAK\")\n",
    "                break\n",
    "            \n",
    "            cnt_scenes +=1 \n",
    "            \n",
    "            scene_id = scene.split(\"/\")[-1].split(\".\")[0]\n",
    "            camera_id = scene_id.split(\"_\")[-1]\n",
    "            car_poses = os.path.join(self.path, \"car_poses\", scene_id + \".json\")\n",
    "            \n",
    "            #print(scene_id, self.train_scenes[:5])\n",
    "            if scene_id+\".jpg\" in self.train_scenes:\n",
    "                phase = 'train'\n",
    "            elif scene_id+\".jpg\" in self.validation_scenes:\n",
    "                phase ='val'\n",
    "            else:    \n",
    "                print(\"phase name not in training or validation split\")\n",
    "                continue\n",
    "                \n",
    "            kk = K[\"Camera_\"+camera_id]#intrinsic_vec_to_mat( K[\"Camera_\"+camera_id])\n",
    "            \n",
    "            path_im = scene\n",
    "            \n",
    "            # Run IoU with pifpaf detections and save\n",
    "            path_pif = os.path.join(self.dir_ann, scene_id+\".jpg\" + '.pifpaf.json')\n",
    "            \n",
    "            if os.path.isfile(path_pif) and False:\n",
    "                boxes_gt, boxes_3d, kps, ys = self.extract_ground_truth_pifpaf(car_poses,camera_id, scene_id)\n",
    "            else:\n",
    "                boxes_gt_list, boxes_3d_list, kps_list, ys_list = self.extract_ground_truth(car_poses,camera_id, scene_id)\n",
    "                \n",
    "   \n",
    "            self.dic_names[scene_id+\".jpg\"]['boxes'] = copy.deepcopy(list(boxes_gt_list))\n",
    "            self.dic_names[scene_id+\".jpg\"]['ys'] = copy.deepcopy(ys_list)\n",
    "            self.dic_names[scene_id+\".jpg\"]['K'] = copy.deepcopy(intrinsic_vec_to_mat(kk).transpose().tolist())\n",
    "\n",
    "            \n",
    "            for kps, ys, boxes_gt, boxes_3d in zip(kps_list, ys_list, boxes_gt_list, boxes_3d_list):\n",
    "                \n",
    "                \n",
    "                kps = [kps.transpose().tolist()]\n",
    "                #kk = list(intrinsic_vec_to_mat(kk).transpose())\n",
    "                \n",
    "                self.dic_jo[phase]['kps'].append(kps)\n",
    "                \n",
    "                inp = preprocess_monoloco(kps,  intrinsic_vec_to_mat(kk).transpose().tolist()).view(-1).tolist()\n",
    "                #print(\"inp\", inp)\n",
    "                self.dic_jo[phase]['X'].append(inp)\n",
    "                lab = normalize_hwl(ys)\n",
    "                self.dic_jo[phase]['Y'].append(list(lab))\n",
    "                self.dic_jo[phase]['names'].append(scene_id+\".jpg\")  # One image name for each annotation\n",
    "                self.dic_jo[phase]['boxes_3d'].append(list(boxes_3d))\n",
    "                self.dic_jo[phase]['K'].append(intrinsic_vec_to_mat(kk).transpose().tolist())\n",
    "                append_cluster(self.dic_jo, phase, list(inp), list(lab), kps)\n",
    "                cnt_ann += 1\n",
    "                sys.stdout.write('\\r' + 'Saved annotations {}'.format(cnt_ann) + '\\t')\n",
    "\n",
    "        with open(os.path.join(self.path_joints), 'w') as f:\n",
    "            \"\"\"\n",
    "           print(self.dic_jo['train'].keys())\n",
    "            print(self.dic_jo['train']['names'])\n",
    "            print(self.dic_jo['train']['X'])\n",
    "            print(self.dic_jo['train']['Y'])\n",
    "            print(self.dic_jo['train']['kps'])\n",
    "            print(self.dic_jo['train']['K'])\n",
    "            print(self.dic_jo['train']['boxes_3d'])\n",
    "            print(self.dic_jo['train']['clst'])\"\"\"\n",
    "            json.dump(self.dic_jo, f)\n",
    "        with open(os.path.join(self.path_names), 'w') as f:\n",
    "            json.dump(self.dic_names, f)\n",
    "        end = time.time()\n",
    "\n",
    "        extract_box_average(self.dic_jo['train']['boxes_3d'])\n",
    "        print(\"\\nSaved {} annotations for {} scenes. Total time: {:.1f} minutes\"\n",
    "              .format(cnt_ann, cnt_scenes, (end-start)/60))\n",
    "        print(\"\\nOutput files:\\n{}\\n{}\\n\".format(self.path_names, self.path_joints))\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Same procedure as extract_ground_truth but for the pifpaf keypoints.               \n",
    "                           \n",
    "\n",
    "            \n",
    "                    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factory(dataset, dir_apollo):\n",
    "    \"\"\"Define dataset type and split training and validation\"\"\"\n",
    "\n",
    "    assert dataset in ['train', '3d_car_instance_sample']\n",
    "\n",
    "    path = os.path.join(dir_apollo, dataset)\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        \n",
    "        with open(os.path.join(path, \"split\", \"train-list.txt\"), \"r\") as file:\n",
    "            train_scenes = file.read().splitlines()\n",
    "        #scenes = [scene for scene in scenes if scene['token'] in train_scenes]\n",
    "        with open(os.path.join(path, \"split\", \"validation-list.txt\"), \"r\") as file:\n",
    "            validation_scenes = file.read().splitlines()\n",
    "            \n",
    "    elif dataset == '3d_car_instance_sample':\n",
    "        with open(os.path.join(path, \"split\", \"train-list.txt\"), \"r\") as file:\n",
    "            train_scenes = file.read().splitlines()\n",
    "        #scenes = [scene for scene in scenes if scene['token'] in train_scenes]\n",
    "        with open(os.path.join(path, \"split\", \"validation-list.txt\"), \"r\") as file:\n",
    "            validation_scenes = file.read().splitlines()\n",
    "    \n",
    "    path_img = os.path.join(path, \"images\")\n",
    "    scenes = [os.path.join(path_img, file) for file in os.listdir(path_img) if file.endswith(\".jpg\")]\n",
    "    \n",
    "    return scenes, train_scenes, validation_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = PreprocessApolloscape(dir_ann, dir_apollo, dir_out, dataset, kps_3d = kps_3d, buffer = buffer, radius = radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotations 49287\t[2.06495164 4.6784814  1.56490185]\n",
      "[0.12742667 0.34594963 0.17204898]\n",
      "\n",
      "Saved 49287 annotations for 4283 scenes. Total time: 46.4 minutes\n",
      "\n",
      "Output files:\n",
      "/home/maximebonnesoeur/monstereo/data/arrays/names-train-201016-1341.json\n",
      "/home/maximebonnesoeur/monstereo/data/arrays/joints-train-201016-1341.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
